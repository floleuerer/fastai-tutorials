{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run this notebook in Colab and Chrome!** (On github.com right-click the \"Open in Colab\" badge -> \"open in new tab\").\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/floleuerer/fastai-tutorials/blob/main/fastai_tensorboard_projector.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -Uqq fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorboard Projector with fastai\n",
    "\n",
    "With fastai's TensorBoardProjectorCallback it's really easy to visualize **Image Embeddings** in Tensorboard Projector. There are two options:\n",
    "\n",
    "\n",
    "1.   write image embeddings during training (use `TensorBoardCallback(projector=True)` during training)\n",
    "2.   write image embeddings during inference e.g. to use a different dataset than the model was trained on (use `TensorBoardProjectorCallback()` during inference)\n",
    "\n",
    "I'll show how to use TensorBoardProjectorCallback during inference!\n",
    "\n",
    "For more information on the tensorboard-Integration see https://docs.fast.ai/callback.tensorboard.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model\n",
    "\n",
    "We could just use a plain pretrained model to extract the image embeddings. But fine-tuning a model on the dataset or domain you are going to use, gives more meaningful features and embeddings.\n",
    "\n",
    "In this tutorial we use the **Pets** dataset and fine-tune a **Resnet34** (see the [fastai docs](https://docs.fast.ai/tutorial.vision) for more information)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.PETS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeller = using_attr(RegexLabeller(pat = r'^(.*)_\\d+.jpg$'), 'name')\n",
    "\n",
    "blocks = DataBlock(blocks=(ImageBlock, CategoryBlock), \n",
    "                 get_items=get_image_files, \n",
    "                 get_y=labeller,\n",
    "                 splitter=RandomSplitter(valid_pct=0.2, seed=42),\n",
    "                 item_tfms=Resize(224))\n",
    "\n",
    "dls = blocks.dataloaders(path/'images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = cnn_learner(dls, resnet34, metrics=accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fine_tune(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Image Embeddings during Inference\n",
    "\n",
    "We'll create a Dataloader for a subset of the Pets-dataset and run inference with the `TensorBoardProjectorCallback()`to write the image embeddings. Then we'll use **tensorboard** to visualize the embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.callback.tensorboard import TensorBoardProjectorCallback\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only colab - workaround for bug https://github.com/PyTorchLightning/pytorch-lightning/issues/4214\n",
    "import tensorflow as tf\n",
    "import tensorboard as tb\n",
    "tf.io.gfile = tb.compat.tensorflow_stub.io.gfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the datloader for 256 images using `learn.dls.test_dl()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = get_image_files(path/'images')\n",
    "random.shuffle(files)\n",
    "files = files[:256]\n",
    "dl = learn.dls.test_dl(files, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run `learn.get_preds()` and pass the dataloader and the `TensorBoardProjectorCallback()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbs = [TensorBoardProjectorCallback(log_dir='proj')]\n",
    "_ = learn.get_preds(dl=dl, cbs=cbs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Embeddings in Tensorboard Projector\n",
    "\n",
    "Run tensorboard in the Notebook - Make sure to switch to **Projector** in the drop-down on the top-right corner. Du to colab's slow i/o the 'Fetching sprite image...' step can take a while.  You can switch between the different dimensional reduction algoritms on the left (PCA, t-SNE and UMAP)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Projector](imgs/tb_projector.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir /content/proj"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastaidev",
   "language": "python",
   "name": "fastaidev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
